{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Index","text":""},{"location":"getting-start/","title":"Getting Started with Lakehouse Lab","text":"<p>This guide will walk you through the prerequisites, installation, configuration, and usage of Lakehouse Lab.</p>"},{"location":"getting-start/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Node 23.5.0 or higher</li> <li>Golang 1.24 or higher</li> <li>Python 3.12 or higher</li> <li>Poetry 1.8.5 \u2013 a dependency management tool for Python</li> <li>Docker 27.4.0 or higher</li> </ul>"},{"location":"getting-start/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>Clone the repository from GitHub and change to the project directory:</p> <pre><code>git clone https://github.com/FabioCaffarello/lakehouse-lab.git\ncd lakehouse-lab\n</code></pre>"},{"location":"getting-start/#2-set-up-the-virtual-environment","title":"2. Set Up the Virtual Environment","text":"<p>Set up the project with a single command:</p> <pre><code>make setup\n</code></pre> <p>This command will:</p> <ul> <li>Create a virtual environment in the <code>.venv</code> directory.</li> <li>Install all dependencies (including development and documentation extras).</li> <li>Set up pre-commit hooks for both commit and push stages.</li> </ul>"},{"location":"getting-start/#3-running-the-service","title":"3. Running the Service","text":"<p>To start the development server with auto-reload enabled, run:</p> <pre><code>make run\n</code></pre> <p>This command launches the Lakehouse Lab service, making the REST API available for testing and integration.</p>"},{"location":"getting-start/#4-running-tests","title":"4. Running Tests","text":"<p>To run the entire test suite, use the following command:</p> <pre><code>make check-all\n</code></pre> <p>This command executes all tests with <code>pytest</code> in the controlled environment and outputs the results along with a coverage report.</p>"},{"location":"getting-start/#5-linting-and-code-quality","title":"5. Linting and Code Quality","text":"<p>To keep your code clean and consistent, use these commands:</p> <ul> <li>Lint Code (using Ruff):</li> </ul> <pre><code>make lint\n</code></pre> <ul> <li>Run Pre-commit Hooks:</li> </ul> <pre><code>make precommit\n</code></pre>"},{"location":"getting-start/#6-documentation","title":"6. Documentation","text":""},{"location":"getting-start/#serve-documentation-locally","title":"Serve Documentation Locally","text":"<p>The project documentation is managed with MkDocs. To serve it locally with live reload, run:</p> <pre><code>make server-docs\n</code></pre> <p>Then visit http://127.0.0.1:8000 in your browser.</p>"},{"location":"getting-start/#deploy-documentation","title":"Deploy Documentation","text":"<p>To build and deploy the documentation to GitHub Pages:</p> <pre><code>make deploy-docs\n</code></pre> <p>This command builds the docs and pushes them to the appropriate branch for GitHub Pages hosting.</p>"},{"location":"getting-start/#7-additional-commands","title":"7. Additional Commands","text":"<p>For more tasks and a complete list of available commands, run:</p> <pre><code>make help\n</code></pre> <p>This will display a summary of all available Makefile targets and their descriptions.</p>"},{"location":"getting-start/#8-troubleshooting","title":"8. Troubleshooting","text":"<ul> <li>Virtual Environment Issues:   If you experience problems with the virtual environment, try clearing cached files by running:</li> </ul> <pre><code>make clean\nmake setup\n</code></pre> <ul> <li>Pre-commit Hooks Not Running:   If pre-commit hooks aren\u2019t working as expected, install them manually:</li> </ul> <pre><code>pre-commit install\n</code></pre> <ul> <li>Dependency Updates:   When updating dependencies in <code>pyproject.toml</code>, run the following commands to refresh the lock file:</li> </ul> <pre><code>npx nx reset\npoetry update\n</code></pre>"},{"location":"summary/","title":"Summary","text":"<ul> <li>Home</li> <li>Getting Start</li> <li>Services</li> <li>Libs</li> <li>Dependency Graph</li> </ul>"},{"location":"reference/libs/ddd/adapters/api/","title":"API","text":"<p>The API provides an HTTP interface for interacting with the Emulator Service. Built on FastAPI, it leverages modular controllers to coordinate use cases, dependency injection to streamline configuration and resource instantiation, and background tasks to offload long-running emulation processes.</p>"},{"location":"reference/libs/ddd/adapters/api/#features","title":"Features","text":"<ul> <li> <p>RESTful Interface:   Exposes endpoints to trigger and manage emulation processes. A dedicated <code>/emulator</code> endpoint (provided by the controllers library) allows external clients to initiate emulator workflows.</p> </li> <li> <p>Modular Architecture:   Organized into controllers and use cases, the API layer wires these components together within a FastAPI application while maintaining a clear separation of concerns.</p> </li> <li> <p>Dependency Injection:   Utilizes FastAPI\u2019s dependency injection to automatically supply configuration settings, storage clients (Minio), producer implementations (Kafka), and other dependencies.</p> </li> <li> <p>Background Processing:   Emulation tasks run as background jobs via FastAPI\u2019s BackgroundTasks, ensuring that the API remains responsive while handling long-running processes asynchronously.</p> </li> <li> <p>Graceful Shutdown:   A shutdown event hook is available for cleanup tasks, ensuring that resources are properly released when the service stops.</p> </li> </ul>"},{"location":"reference/libs/ddd/adapters/api/#installation","title":"Installation","text":"<p>Install the API library along with its dependencies using your package manager (e.g., Poetry). Make sure you have configured environment variables or settings files for your external resources (e.g., Kafka, Minio).</p> <pre><code>npx nx run &lt;project&gt;:add --name ddd-adapters-api --local\n</code></pre>"},{"location":"reference/libs/ddd/adapters/api/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/adapters/api/#endpoints","title":"Endpoints","text":""},{"location":"reference/libs/ddd/adapters/api/#get","title":"GET <code>/</code>","text":"<p>Returns a welcome message to confirm that the API is running.</p> <p>Example Response:</p> <pre><code>{\n  \"message\": \"Welcome to the Emulator Service REST API!\"\n}\n</code></pre>"},{"location":"reference/libs/ddd/adapters/api/#post-emulator","title":"POST <code>/emulator</code>","text":"<p>Triggers the emulator process using the configuration provided in the request payload (conforming to the <code>StartEmulatorDTO</code> schema). This endpoint invokes the Start Emulator Use Case to set up producers, generate fake data, and schedule a background task.</p> <p>Request Payload Example:</p> <pre><code>{\n  \"emulator_sync\": \"kafka\",\n  \"emulation_domain\": \"transaction\",\n  \"timeout\": 60\n}\n</code></pre> <p>Example Response:</p> <pre><code>{\n  \"id\": \"generated-uuid-string\",\n  \"emulator_sync\": \"kafka\",\n  \"emulation_domain\": \"transaction\",\n  \"timeout\": 60\n}\n</code></pre>"},{"location":"reference/libs/ddd/adapters/api/#configuration","title":"Configuration","text":"<p>The API relies on a configuration object (using a custom <code>Settings</code> class) stored on the FastAPI app state. This configuration provides connection details for Kafka, Minio, and other necessary resources.</p> <p>Example Configuration on Startup:</p> <pre><code>from emulator_settings.settings import Settings\nfrom fastapi import FastAPI\n\napp = FastAPI(\n    title=\"Emulator Service REST API\",\n    description=\"API for the Emulator Service.\",\n    version=\"1.0.0\"\n)\n\napp.state.config = Settings(\n    kafka_bootstrap_servers=\"localhost:9092\",\n    kafka_username=\"your_username\",\n    kafka_password=\"your_password\",\n    minio_endpoint=\"minio.example.com\",\n    minio_access_key=\"your_access_key\",\n    minio_secret_key=\"your_secret_key\",\n    minio_secure=False\n)\n</code></pre>"},{"location":"reference/libs/ddd/adapters/api/#background-tasks-and-graceful-shutdown","title":"Background Tasks and Graceful Shutdown","text":"<ul> <li> <p>Background Tasks:   Emulation processing is executed in the background via FastAPI\u2019s <code>BackgroundTasks</code>, ensuring that requests return promptly while the heavy processing continues asynchronously.</p> </li> <li> <p>Shutdown Hooks:   The <code>@app.on_event(\"shutdown\")</code> decorator registers cleanup functions to handle any necessary resource release or finalization when the service shuts down.</p> </li> </ul>"},{"location":"reference/libs/ddd/adapters/api/#running-the-api","title":"Running the API","text":"<p>To run the API locally, you can use Uvicorn:</p> <pre><code>uvicorn main:app --reload\n</code></pre> <p>Ensure that your application (e.g., the <code>main.py</code> module) includes the API router and configuration, as shown in the usage examples above.</p>"},{"location":"reference/libs/ddd/adapters/api/#testing","title":"Testing","text":"<p>Unit tests for the API controllers and use cases are provided. To run the API tests, execute:</p> <pre><code>npx nx test ddd-adapters-api\n</code></pre>"},{"location":"reference/libs/ddd/adapters/controllers/","title":"Controllers","text":"<p>The Controllers Library encapsulates your HTTP endpoints, providing a RESTful interface for triggering and managing emulator processes. Built on top of FastAPI, the library leverages dependency injection to seamlessly integrate configuration settings, storage clients, and producer strategies into your application. This ensures that your emulator use case is easily accessible via HTTP while maintaining a clean separation of concerns.</p>"},{"location":"reference/libs/ddd/adapters/controllers/#features","title":"Features","text":"<ul> <li> <p>RESTful Endpoints:   Exposes endpoints (e.g., POST <code>/emulator</code>) that accept input via DTOs and return structured responses, enabling external clients to trigger emulator processes.</p> </li> <li> <p>Dependency Injection:   Uses FastAPI\u2019s dependency injection system to automatically obtain configuration parameters and instantiate required dependencies such as Kafka producers, Minio storage clients, and use cases.</p> </li> <li> <p>Centralized Error Handling:   Employs HTTP exceptions with appropriate status codes to manage errors and communicate issues clearly to API consumers.</p> </li> <li> <p>Integration with Background Tasks:   Schedules emulation tasks in the background using FastAPI's BackgroundTasks, ensuring non-blocking request handling during long-running emulation processes.</p> </li> </ul>"},{"location":"reference/libs/ddd/adapters/controllers/#installation","title":"Installation","text":"<p>Add the Controllers library to your monorepo by running:</p> <pre><code>npx nx run &lt;project&gt;:add --name ddd-application-controllers --local\n</code></pre> <p>Ensure that all required dependencies (e.g., FastAPI, confluent-kafka, Faker, and your logger library) are installed via your dependency manager (such as Poetry).</p>"},{"location":"reference/libs/ddd/adapters/controllers/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/adapters/controllers/#configuration-and-dependency-injection","title":"Configuration and Dependency Injection","text":"<p>The controllers rely on FastAPI dependency injection to supply configuration settings (via a custom <code>Settings</code> model) and to instantiate needed clients:</p> <ul> <li>get_config: Retrieves the application\u2019s configuration from the FastAPI app state.</li> <li>get_minio_client: Instantiates a <code>MinioStorageClient</code> using configuration values.</li> <li>get_kafka_producer: Instantiates a <code>KafkaProducerStrategy</code> using configuration values.</li> <li>get_start_emulator_usecase: Combines the above dependencies to construct the <code>StartEmulatorUseCase</code>.</li> </ul>"},{"location":"reference/libs/ddd/adapters/controllers/#endpoints","title":"Endpoints","text":"<p>The library defines an APIRouter under the <code>/emulator</code> prefix with one key endpoint:</p>"},{"location":"reference/libs/ddd/adapters/controllers/#post-emulator","title":"POST <code>/emulator</code>","text":"<ul> <li> <p>Description:   Triggers the emulator process by accepting a <code>StartEmulatorDTO</code> payload and scheduling a background task that produces data using the appropriate producer (Kafka or Minio).</p> </li> <li> <p>Request Body:   Expects a DTO matching <code>StartEmulatorDTO</code>, which includes parameters such as emulator synchronization type, emulation domain, and timeout.</p> </li> <li> <p>Response:   Returns an <code>EmulationScheduledDTO</code> response containing the scheduled emulation details (including a unique emulation ID).</p> </li> <li> <p>Example Request:</p> </li> </ul> <pre><code>POST /emulator HTTP/1.1\nContent-Type: application/json\n\n{\n    \"emulator_sync\": \"kafka\",\n    \"emulation_domain\": \"transaction\",\n    \"timeout\": 60\n}\n</code></pre> <ul> <li>Example Response:</li> </ul> <pre><code>{\n  \"id\": \"generated-uuid-string\",\n  \"emulator_sync\": \"kafka\",\n  \"emulation_domain\": \"transaction\",\n  \"timeout\": 60\n}\n</code></pre>"},{"location":"reference/libs/ddd/adapters/controllers/#integration-example","title":"Integration Example","text":"<p>Here\u2019s a sample integration that uses the Controllers library within a FastAPI application:</p> <pre><code>from fastapi import FastAPI\nfrom controllers.emulator_controller import router as emulator_router\n\napp = FastAPI()\napp.state.config = ...  # Initialize your Settings instance here.\n\n# Include the emulator endpoints\napp.include_router(emulator_router)\n</code></pre>"},{"location":"reference/libs/ddd/adapters/controllers/#configuration-details","title":"Configuration Details","text":"<ul> <li> <p>Settings:   The controllers depend on a <code>Settings</code> class that holds configuration values such as Kafka bootstrap servers, Minio endpoints, and authentication credentials.</p> </li> <li> <p>Dependency Mapping:   The endpoint uses dependency providers to instantiate:</p> </li> <li> <p>A Minio storage client (<code>MinioStorageClient</code>),</p> </li> <li>A Kafka producer strategy (<code>KafkaProducerStrategy</code>),</li> <li> <p>A unified use case (<code>StartEmulatorUseCase</code>) that orchestrates background data emulation tasks.</p> </li> <li> <p>Background Task Scheduling:   Emulation tasks are scheduled using FastAPI\u2019s <code>BackgroundTasks</code>, enabling asynchronous processing of data production without blocking API responses.</p> </li> </ul>"},{"location":"reference/libs/ddd/adapters/controllers/#testing","title":"Testing","text":"<p>Unit tests for the Controllers library are provided and can be executed using your CI command:</p> <pre><code>npx nx test ddd-application-controllers\n</code></pre>"},{"location":"reference/libs/ddd/application/dtos/","title":"DTOs","text":"<p>The DTOs (Data Transfer Objects) Library provides structured representations of emulation data for your application. It simplifies data transfer between different layers and ensures data consistency and validation across the system.</p>"},{"location":"reference/libs/ddd/application/dtos/#features","title":"Features","text":"<ul> <li> <p>Immutable Data Structures:   The <code>EmulationScheduledDTO</code> is implemented as a frozen dataclass, ensuring that once created, its values remain unchanged.</p> </li> <li> <p>Data Validation:   The <code>StartEmulatorDTO</code> leverages Pydantic's <code>BaseModel</code> to validate and parse input data for starting an emulation.</p> </li> <li> <p>Consistent Data Transfer:   Both DTOs encapsulate essential information about an emulation, including synchronization details, domain, timeout settings, and a unique identifier.</p> </li> </ul>"},{"location":"reference/libs/ddd/application/dtos/#installation","title":"Installation","text":"<p>Add the DTOs library to your monorepo by running:</p> <pre><code>npx nx run &lt;project&gt;:add --name ddd-application-dtos --local\n</code></pre> <p>Ensure that your environment includes all required dependencies such as <code>pydantic</code>.</p>"},{"location":"reference/libs/ddd/application/dtos/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/application/dtos/#emulationscheduleddto","title":"EmulationScheduledDTO","text":"<p>The <code>EmulationScheduledDTO</code> is a frozen dataclass representing an emulation's scheduled details. It includes the following fields:</p> <ul> <li>id: An <code>EmulationID</code> value object representing the unique identifier of the emulation.</li> <li>emulator_sync: A string indicating the synchronization details.</li> <li>emulation_domain: A string specifying the emulation domain.</li> <li>timeout: An integer value representing the timeout duration.</li> </ul> <p>Example:</p> <pre><code>from dtos.emulation_dto import EmulationScheduledDTO\nfrom value_objects.emulator_id import EmulationID\n\n# Create an EmulationScheduledDTO instance\nemulation_dto = EmulationScheduledDTO(\n    id=EmulationID.generate(),\n    emulator_sync=\"sync_value\",\n    emulation_domain=\"domain_value\",\n    timeout=30\n)\n\nprint(emulation_dto)\n</code></pre>"},{"location":"reference/libs/ddd/application/dtos/#startemulatordto","title":"StartEmulatorDTO","text":"<p>The <code>StartEmulatorDTO</code> is a Pydantic model used for starting an emulation. It validates the following fields:</p> <ul> <li>emulator_sync: A string indicating synchronization details.</li> <li>emulation_domain: A string specifying the emulation domain.</li> <li>timeout: An integer value representing the timeout duration.</li> </ul> <p>Example:</p> <pre><code>from dtos.emulation_dto import StartEmulatorDTO\n\n# Define data for starting an emulation\ndata = {\n    \"emulator_sync\": \"sync_value\",\n    \"emulation_domain\": \"domain_value\",\n    \"timeout\": 30\n}\n\n# Parse and validate the data using StartEmulatorDTO\nstart_dto = StartEmulatorDTO(**data)\nprint(start_dto)\n</code></pre>"},{"location":"reference/libs/ddd/application/dtos/#configuration-details","title":"Configuration Details","text":"<ul> <li> <p>Immutable DTO: <code>EmulationScheduledDTO</code> is implemented with <code>@dataclass(frozen=True)</code> to ensure immutability, promoting data integrity across your application.</p> </li> <li> <p>Robust Validation: <code>StartEmulatorDTO</code> uses Pydantic's powerful data validation and parsing features to ensure that only valid data is processed when starting an emulation.</p> </li> </ul>"},{"location":"reference/libs/ddd/application/dtos/#testing","title":"Testing","text":"<p>Unit tests are not included in this library. However, can be created if needed (remember to edit the test command in the project.json to not pass in failures). To run the tests, navigate to the library directory and execute:</p> <pre><code>npx nx test ddd-application-dtos\n</code></pre>"},{"location":"reference/libs/ddd/application/usecases/","title":"Use Cases","text":"<p>The Use Cases Library provides core application logic that orchestrates various components like messaging producers, fake data generators, and storage clients to implement real-world business scenarios. A primary example is the Start Emulator Use Case, which starts an emulation process by coordinating between Kafka/Minio producers, data factories, and FastAPI's background tasks.</p>"},{"location":"reference/libs/ddd/application/usecases/#features","title":"Features","text":"<ul> <li> <p>Abstract Sync Producer Interface:   Defines a uniform interface (<code>SyncProducer</code>) for synchronous message production across multiple systems (e.g., Kafka or Minio).</p> </li> <li> <p>Producer Wrapper Implementations:   Includes concrete implementations for Kafka (<code>KafkaFactorySyncProducerWrapper</code>) and Minio (<code>MinioFactorySyncProducerWrapper</code>). These wrappers encapsulate system-specific resource setup and message production.</p> </li> <li> <p>Flexible Data Emulation:   Uses various fake data factories to generate realistic transaction, device log, or user profile data, simulating actual operational data flows.</p> </li> <li> <p>Background Task Scheduling:   Integrates with FastAPI's <code>BackgroundTasks</code> to schedule long-running emulation tasks in a non-blocking manner.</p> </li> <li> <p>Resource Setup and Parallel Production:   Ensures that required resources (Kafka topics or Minio buckets) are created if missing. Supports parallel data production using multiple threads with proper synchronization and graceful shutdown using timers.</p> </li> </ul>"},{"location":"reference/libs/ddd/application/usecases/#installation","title":"Installation","text":"<p>Add the Use Cases library to your monorepo by running:</p> <pre><code>npx nx run &lt;project&gt;:add --name ddd-application-usecases --local\n</code></pre> <p>Ensure that all required dependencies (such as confluent-kafka, fastapi, Faker, and your logger library) are installed via your dependency manager (e.g., Poetry).</p>"},{"location":"reference/libs/ddd/application/usecases/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/application/usecases/#instantiating-producer-wrappers","title":"Instantiating Producer Wrappers","text":"<p>Depending on your infrastructure, instantiate the appropriate producer wrapper:</p>"},{"location":"reference/libs/ddd/application/usecases/#kafka-producer-wrapper","title":"Kafka Producer Wrapper","text":"<pre><code>from producers.kafka.producer import KafkaProducerStrategy\nfrom ddd.application.usecases.start_emulator import KafkaFactorySyncProducerWrapper\n\n# Create a Kafka producer strategy instance (configure bootstrap servers, etc.)\nkafka_producer = KafkaProducerStrategy(\n    bootstrap_servers=\"localhost:9092\",\n    kafka_username=\"your_username\",  # Optional, for SASL_SSL configuration\n    kafka_password=\"your_password\"   # Optional, for SASL_SSL configuration\n)\n\n# Wrap the Kafka producer\nkafka_wrapper = KafkaFactorySyncProducerWrapper(\n    kafka_producer=kafka_producer,\n    kafka_brokers=\"localhost:9092\"\n)\n</code></pre>"},{"location":"reference/libs/ddd/application/usecases/#minio-producer-wrapper","title":"Minio Producer Wrapper","text":"<pre><code>from storage.minio.storage import MinioStorageClient\nfrom ddd.application.usecases.start_emulator import MinioFactorySyncProducerWrapper\n\n# Initialize the Minio client with your Minio endpoint and credentials.\nminio_client = MinioStorageClient(\n    endpoint=\"minio.example.com\",\n    access_key=\"your_access_key\",\n    secret_key=\"your_secret_key\",\n    secure=False  # Set to True if using HTTPS\n)\n\n# Wrap the Minio client\nminio_wrapper = MinioFactorySyncProducerWrapper(minio_client)\n</code></pre>"},{"location":"reference/libs/ddd/application/usecases/#starting-the-emulator","title":"Starting the Emulator","text":"<p>The Start Emulator Use Case coordinates the emulation start process. It:</p> <ul> <li>Determines the target resource (Kafka topic or Minio bucket) based on the domain.</li> <li>Retrieves the corresponding fake data factory.</li> <li>Schedules a background task to continuously produce messages using multiple parallel threads until the emulation timeout is reached.</li> </ul>"},{"location":"reference/libs/ddd/application/usecases/#example","title":"Example","text":"<pre><code>from fastapi import FastAPI, BackgroundTasks\nfrom ddd.application.usecases.start_emulator import StartEmulatorUseCase\nfrom producers.kafka.producer import KafkaProducerStrategy\nfrom storage.minio.storage import MinioStorageClient\nfrom dtos.emulation_dto import StartEmulatorDTO\n\n# Create your FastAPI app\napp = FastAPI()\n\n# Create instances for Kafka and Minio components.\nkafka_producer = KafkaProducerStrategy(\n    bootstrap_servers=\"localhost:9092\",\n    kafka_username=\"your_username\",\n    kafka_password=\"your_password\"\n)\nminio_client = MinioStorageClient(\n    endpoint=\"minio.example.com\",\n    access_key=\"your_access_key\",\n    secret_key=\"your_secret_key\",\n    secure=False\n)\n\n# Instantiate the use case with both producer implementations.\nstart_emulator_usecase = StartEmulatorUseCase(\n    kafka_producer=kafka_producer,\n    kafka_brokers=\"localhost:9092\",\n    minio_client=minio_client\n)\n\n@app.post(\"/start-emulator\")\ndef start_emulator(dto: StartEmulatorDTO, background_tasks: BackgroundTasks):\n    # Specify the number of parallel threads (e.g., 5)\n    emulation_scheduled = start_emulator_usecase.execute(dto, background_tasks, num_threads=5)\n    return emulation_scheduled\n</code></pre>"},{"location":"reference/libs/ddd/application/usecases/#key-components","title":"Key Components","text":"<ul> <li> <p>SyncProducer (Abstract Base Class):   Defines the contract for producers with methods like <code>produce()</code>, <code>flush()</code>, and <code>setup_resource()</code>. This ensures consistent behavior across different implementations.</p> </li> <li> <p>Producer Wrappers:</p> </li> <li> <p>KafkaFactorySyncProducerWrapper:     Uses Confluent Kafka's producer to send JSON messages and automatically creates topics if necessary.</p> </li> <li> <p>MinioFactorySyncProducerWrapper:     Uses Minio to upload messages as JSON objects into a bucket. Here, the <code>flush()</code> operation is a no-op.</p> </li> <li> <p>Background Emulation Task:   The use case schedules an emulation task in the background. It spawns multiple threads that invoke <code>produce_data()</code> repeatedly until a specified timeout, then flushes the producer and logs the completion of the emulation.</p> </li> </ul>"},{"location":"reference/libs/ddd/application/usecases/#configuration-details","title":"Configuration Details","text":"<ul> <li> <p>Resource Mapping:   The use case internally maps emulation domains (e.g., \"transaction\", \"user-profile\", \"device-log\") to target topics or buckets. A default topic is used for unsupported domains.</p> </li> <li> <p>Factory Mapping:   Associates each domain with the corresponding fake data factory to generate realistic records.</p> </li> <li> <p>Parallel Processing:   Implements thread-based parallelism for high-throughput emulation. A global stop event and timer are used to gracefully shut down production.</p> </li> </ul>"},{"location":"reference/libs/ddd/application/usecases/#testing","title":"Testing","text":"<p>Unit tests are provided for this use case within the tests folder. The test suite verifies correct producer selection, resource setup, task scheduling, and proper execution of parallel data production.</p> <p>To run the tests:</p> <pre><code>npx nx test ddd-application-usecases\n</code></pre>"},{"location":"reference/libs/ddd/entities/","title":"Entities","text":"<p>The Entities Library provides domain entities that encapsulate business logic and data for your application. It currently includes the <code>Emulation</code> entity, which represents an emulation instance with a unique identifier, a timeout value, an emulator type, and a timestamp indicating when it was created.</p>"},{"location":"reference/libs/ddd/entities/#features","title":"Features","text":"<ul> <li> <p>Unique Identification:   Each <code>Emulation</code> entity is assigned a unique identifier using the <code>EmulationID</code> value object. This ensures that every emulation instance can be uniquely referenced.</p> </li> <li> <p>Automatic Timestamping:   The entity records its creation time (<code>created_at</code>) automatically using the current UTC datetime.</p> </li> <li> <p>Flexible Data Structure:   The <code>Emulation</code> entity includes core attributes such as <code>timeout</code> and <code>emulator_type</code>, and it can be easily extended to accommodate additional properties.</p> </li> <li> <p>Easy Serialization:   The <code>to_dict</code> method converts the entity to a dictionary, making it simple to serialize data for APIs, logging, or other integrations.</p> </li> </ul>"},{"location":"reference/libs/ddd/entities/#installation","title":"Installation","text":"<p>Add the Entities library to your monorepo by running:</p> <pre><code>npx nx run &lt;project&gt;:add --name ddd-entities --local\n</code></pre>"},{"location":"reference/libs/ddd/entities/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/entities/#creating-an-emulation-entity","title":"Creating an Emulation Entity","text":"<p>To create an instance of an <code>Emulation</code> entity, simply import the class and instantiate it with the required parameters:</p> <pre><code>from entities.emulation import Emulation\n\n# Create an Emulation entity with a timeout of 30 and a specified emulator type.\nemulation = Emulation(timeout=30, emulator_type=\"test_emulator\")\nprint(emulation.to_dict())\n</code></pre>"},{"location":"reference/libs/ddd/entities/#understanding-the-attributes","title":"Understanding the Attributes","text":"<ul> <li> <p>id:   A unique identifier automatically generated using the <code>EmulationID</code> value object.</p> </li> <li> <p>timeout:   An integer representing the timeout period for the emulation.</p> </li> <li> <p>emulator_type:   A string specifying the type of emulator.</p> </li> <li> <p>created_at:   A UTC timestamp indicating when the emulation was created.</p> </li> </ul>"},{"location":"reference/libs/ddd/entities/#testing","title":"Testing","text":"<p>Unit tests are included to ensure that the <code>Emulation</code> entity behaves as expected. To run the tests, navigate to the library directory and execute:</p> <pre><code>npx nx test ddd-entities\n</code></pre>"},{"location":"reference/libs/ddd/infra/producers/","title":"Producers","text":"<p>The Producers Library provides a unified interface for producing messages to external systems, with a focus on Kafka messaging. This library includes a base producer abstraction and a concrete Kafka producer implementation. It is designed to be extensible, allowing future support for additional messaging systems while maintaining a consistent API.</p>"},{"location":"reference/libs/ddd/infra/producers/#features","title":"Features","text":"<ul> <li>Unified Producer Interface:   Defines a standard interface (<code>BaseProducer</code>) for message production across different platforms.</li> <li> <p>Kafka Producer Implementation:   Provides a robust implementation (<code>KafkaProducerStrategy</code>) using Confluent Kafka for producing messages to Kafka topics.</p> </li> <li> <p>Configurable and Secure:   Supports both plaintext and SASL_SSL configurations for secure message production.</p> </li> <li> <p>Callback and Delivery Reporting:   Includes a delivery report mechanism that logs successful and failed message deliveries.</p> </li> </ul>"},{"location":"reference/libs/ddd/infra/producers/#installation","title":"Installation","text":"<p>To add the Producers library to your monorepo, run:</p> <pre><code>npx nx run &lt;project&gt;:add --name ddd-infra-producers --local\n</code></pre> <p>Ensure your environment includes all required dependencies, such as <code>confluent_kafka</code> and your logger library.</p>"},{"location":"reference/libs/ddd/infra/producers/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/infra/producers/#instantiating-the-kafka-producer","title":"Instantiating the Kafka Producer","text":"<p>Import and create an instance of the <code>KafkaProducerStrategy</code> with the necessary configuration:</p> <pre><code>from producers.infra.producers.kafka.producer import KafkaProducerStrategy\n\n# Initialize the Kafka producer with bootstrap servers and, optionally, SASL credentials.\nkafka_producer = KafkaProducerStrategy(\n    bootstrap_servers=\"localhost:9092\",\n    kafka_username=\"your_username\",  # Optional\n    kafka_password=\"your_password\"   # Optional\n)\n</code></pre>"},{"location":"reference/libs/ddd/infra/producers/#producing-messages","title":"Producing Messages","text":"<p>To produce a message to a Kafka topic, use the <code>produce</code> method. The message value should be a dictionary that will be JSON-encoded before sending:</p> <pre><code>topic = \"my_topic\"\nkey = \"unique_key\"\nvalue = {\"event\": \"user_signup\", \"user_id\": 12345}\n\n# Produce a message to the specified topic.\nkafka_producer.produce(topic, key, value)\n</code></pre> <p>The producer immediately polls for delivery events and logs the outcome using the configured callback.</p>"},{"location":"reference/libs/ddd/infra/producers/#flushing-the-producer","title":"Flushing the Producer","text":"<p>When you need to ensure that all queued messages have been sent, call the <code>flush</code> method:</p> <pre><code># Flush any remaining messages with a timeout (in seconds).\nkafka_producer.flush(timeout=30)\n</code></pre>"},{"location":"reference/libs/ddd/infra/producers/#delivery-reporting","title":"Delivery Reporting","text":"<p>The producer's delivery report callback logs whether messages are successfully delivered or if they encountered errors. You can customize this behavior by extending or overriding the default callback.</p>"},{"location":"reference/libs/ddd/infra/producers/#configuration-details","title":"Configuration Details","text":"<ul> <li> <p>Producer Configuration:   The Kafka producer is configured with options for batching, compression, and buffering. By default, it uses gzip compression and a client ID of \"emulator-producer\".</p> </li> <li> <p>If SASL credentials are provided, the producer is configured to use SASL_SSL.</p> </li> <li> <p>Otherwise, the producer uses PLAINTEXT.</p> </li> <li> <p>Callback Function:   The <code>delivery_report</code> method is used as a callback for reporting message delivery status. Successful deliveries and errors are both logged for troubleshooting and auditing.</p> </li> </ul>"},{"location":"reference/libs/ddd/infra/producers/#testing","title":"Testing","text":"<p>Unit tests are provided to ensure that all functionality works as expected. To run the tests, navigate to the library\u2019s directory and execute:</p> <pre><code>npx nx test ddd-infra-producers\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/","title":"Storage","text":"<p>The Storage Library provides a unified interface for interacting with bucket-based storage systems. Currently, it includes an implementation for Minio via the <code>MinioStorageClient</code>. The design is extensible so that future implementations (e.g., AWS S3, Google Cloud Storage) can be added seamlessly by conforming to the <code>StorageClient</code> interface.</p>"},{"location":"reference/libs/ddd/infra/storage/#features","title":"Features","text":"<ul> <li>Unified Interface:   Implements a common interface (<code>StorageClient</code>) for storage operations, ensuring consistent usage across different providers.</li> <li> <p>Bucket Operations:   Supports creating buckets, listing buckets, and listing objects within buckets.</p> </li> <li> <p>Object Operations:   Provides methods to upload files or raw bytes (or BytesIO data) and to download files either as local files or as bytes.</p> </li> <li> <p>URI Generation:   Generates URIs for accessing stored objects, making integration with external systems easier.</p> </li> </ul>"},{"location":"reference/libs/ddd/infra/storage/#installation","title":"Installation","text":"<p>Add the Storage library to your monorepo by running:</p> <pre><code>npx nx run &lt;project&gt;:add --name ddd-infra-storage --local\n</code></pre> <p>Ensure that your environment has all required dependencies, including <code>minio</code> and your logger library.</p>"},{"location":"reference/libs/ddd/infra/storage/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/infra/storage/#instantiating-the-minio-storage-client","title":"Instantiating the Minio Storage Client","text":"<p>To begin using the Minio storage client, import and instantiate <code>MinioStorageClient</code> with the appropriate connection parameters:</p> <pre><code>from storage.minio.storage import MinioStorageClient\n\n# Initialize the client with your Minio endpoint and credentials.\nminio_client = MinioStorageClient(\n    endpoint=\"minio.example.com\",\n    access_key=\"your_access_key\",\n    secret_key=\"your_secret_key\",\n    secure=False\n)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#creating-a-bucket","title":"Creating a Bucket","text":"<p>Create a new bucket on the Minio server:</p> <pre><code>bucket_name = \"my_bucket\"\nminio_client.create_bucket(bucket_name)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#listing-buckets","title":"Listing Buckets","text":"<p>Retrieve a list of all buckets available on the Minio server:</p> <pre><code>buckets = minio_client.list_buckets()\nprint(\"Buckets:\", buckets)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#uploading-files-and-bytes","title":"Uploading Files and Bytes","text":""},{"location":"reference/libs/ddd/infra/storage/#upload-a-file","title":"Upload a File","text":"<p>Upload a local file to a specified bucket and obtain its URI:</p> <pre><code>uri = minio_client.upload_file(\"my_bucket\", \"example.txt\", \"path/to/local/file.txt\")\nprint(\"File uploaded to:\", uri)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#upload-raw-bytes","title":"Upload Raw Bytes","text":"<p>Upload data as bytes (or using a BytesIO instance) and get its URI:</p> <pre><code># Upload using raw bytes\nuri = minio_client.upload_bytes(\"my_bucket\", \"data.txt\", b\"Sample data\")\nprint(\"Data uploaded to:\", uri)\n\n# Upload using a BytesIO instance\nfrom io import BytesIO\nbytes_io = BytesIO(b\"Sample data from BytesIO\")\nuri = minio_client.upload_bytes(\"my_bucket\", \"data_bytesio.txt\", bytes_io)\nprint(\"Data uploaded to:\", uri)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#downloading-files-and-bytes","title":"Downloading Files and Bytes","text":""},{"location":"reference/libs/ddd/infra/storage/#download-a-file-locally","title":"Download a File Locally","text":"<p>Download an object from a bucket and save it to a local file:</p> <pre><code>minio_client.download_file(\"my_bucket\", \"example.txt\", \"path/to/save/example.txt\")\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#download-as-bytes","title":"Download as Bytes","text":"<p>Download an object from a bucket and obtain its data as bytes:</p> <pre><code>data = minio_client.download_file_as_bytes(\"my_bucket\", \"example.txt\")\nprint(\"Downloaded data:\", data)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#listing-objects-in-a-bucket","title":"Listing Objects in a Bucket","text":"<p>Retrieve a list of object names stored in a specific bucket:</p> <pre><code>objects = minio_client.list_objects(\"my_bucket\")\nprint(\"Objects in bucket:\", objects)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#generating-object-uris","title":"Generating Object URIs","text":"<p>Generate a URI to access an object stored in a bucket:</p> <pre><code>uri = minio_client.get_uri(\"my_bucket\", \"example.txt\")\nprint(\"Access URI:\", uri)\n</code></pre>"},{"location":"reference/libs/ddd/infra/storage/#configuration-details","title":"Configuration Details","text":"<ul> <li> <p>Minio Connection:   The client is configured with the Minio server\u2019s endpoint and credentials. Use the <code>secure</code> flag to toggle between HTTP and HTTPS.</p> </li> <li> <p>Logging:   All operations log detailed messages using the integrated logger. Adjust or replace the logger if needed.</p> </li> <li> <p>Extensibility:   The library is designed around the <code>StorageClient</code> interface. Future implementations for other storage providers can be added with minimal changes to the application code.</p> </li> </ul>"},{"location":"reference/libs/ddd/infra/storage/#testing","title":"Testing","text":"<p>Unit tests are provided to ensure that all functionality works as expected. To run the tests, navigate to the library\u2019s directory and execute:</p> <pre><code>npx nx test ddd-infra-storage\n</code></pre>"},{"location":"reference/libs/ddd/value-objects/","title":"Value Objects","text":"<p>The Value Objects Library provides a set of immutable objects to represent domain values consistently and reliably. It includes the <code>EmulationID</code> value object, which encapsulates a unique identifier for emulation instances using a UUID format.</p>"},{"location":"reference/libs/ddd/value-objects/#features","title":"Features","text":"<ul> <li>Immutable Data Structures: Uses Python\u2019s <code>@dataclass(frozen=True)</code> to ensure immutability.</li> <li>UUID Validation: Automatically validates that any provided identifier conforms to the UUID format.</li> <li>Convenience Method: Includes a class method to generate a new, valid <code>EmulationID</code>.</li> </ul>"},{"location":"reference/libs/ddd/value-objects/#installation","title":"Installation","text":"<pre><code>npx nx run &lt;project&gt;:add --name ddd-value-objects --local\n</code></pre>"},{"location":"reference/libs/ddd/value-objects/#usage","title":"Usage","text":""},{"location":"reference/libs/ddd/value-objects/#creating-an-emulationid","title":"Creating an EmulationID","text":"<p>Instantiate an <code>EmulationID</code> with a valid UUID string:</p> <pre><code>from value_objects.emulation_id import EmulationID\n\n# Create an EmulationID using a valid UUID string\nemulation_id = EmulationID(\"123e4567-e89b-12d3-a456-426614174000\")\nprint(emulation_id.value)\n</code></pre>"},{"location":"reference/libs/ddd/value-objects/#generating-a-new-emulationid","title":"Generating a New EmulationID","text":"<p>Generate a new unique <code>EmulationID</code> using the provided class method:</p> <pre><code>from value_objects.emulation_id import EmulationID\n\n# Generate a new EmulationID\nnew_id = EmulationID.generate()\nprint(new_id.value)\n</code></pre>"},{"location":"reference/libs/ddd/value-objects/#handling-invalid-ids","title":"Handling Invalid IDs","text":"<p>If an invalid UUID is provided, the class raises a <code>ValueError</code> during initialization:</p> <pre><code>from value_objects.emulation_id import EmulationID\n\ntry:\n    invalid_id = EmulationID(\"invalid-uuid\")\nexcept ValueError as e:\n    print(e)  # Output: \"Invalid EmulationID: invalid-uuid\"\n</code></pre>"},{"location":"reference/libs/ddd/value-objects/#testing","title":"Testing","text":"<p>Unit tests are provided to ensure that the value objects behave as expected. To run the tests, navigate to the <code>libs/shared/value-objects</code> directory and execute:</p> <pre><code>npx nx test ddd-value-objects\n</code></pre>"},{"location":"reference/libs/fake-factory/","title":"Fake Factory","text":"<p>The Fake Factory Library provides a collection of data generation factories designed to simulate realistic, synthetic data for testing, development, and feature store ingestion. Built on top of the Faker library, it offers a flexible base factory and specialized implementations that generate fraud-related records, such as device logs, transactions, and user profiles.</p>"},{"location":"reference/libs/fake-factory/#features","title":"Features","text":"<ul> <li> <p>Extensible Base Factory:   The library defines a <code>BaseFakeFactory</code> interface that can be extended to create new factories with custom logic.</p> </li> <li> <p>Realistic Data Generation:   Leveraging the Faker library, each factory produces synthetic yet realistic data, including names, emails, timestamps, and more.</p> </li> <li> <p>Fraud Simulation:   Specialized factories (e.g., for device logs, transactions, and user profiles) implement fraud rules to simulate various risk scenarios, enabling testing of fraud detection systems and data pipelines.</p> </li> <li> <p>Configurability:   Factories include configurable parameters (e.g., user ID ranges) and randomness to mimic real-world variability and edge cases.</p> </li> </ul>"},{"location":"reference/libs/fake-factory/#installation","title":"Installation","text":"<p>Add the Fake-Factory library to your monorepo by running:</p> <pre><code>npx nx run &lt;project&gt;:add --name fake-factory --local\n</code></pre> <p>Ensure that your environment includes the required dependencies (e.g., Faker) as defined in the <code>pyproject.toml</code> and <code>poetry.toml</code> files.</p>"},{"location":"reference/libs/fake-factory/#usage","title":"Usage","text":""},{"location":"reference/libs/fake-factory/#base-factory","title":"Base Factory","text":"<p>The <code>BaseFakeFactory</code> is the abstract base class that all specific factories extend. It defines the contract for generating fake records.</p> <pre><code>from fake_factory.base_factory import BaseFakeFactory\n\nclass MyFactory(BaseFakeFactory):\n    def generate(self) -&gt; dict[str, Any]:\n        # Implement record generation logic here.\n        return {\"dummy\": \"data\"}\n</code></pre>"},{"location":"reference/libs/fake-factory/#device-log-factory","title":"Device Log Factory","text":"<p>The <code>DeviceLogFactory</code> generates fake device log records, including unique log IDs, device details, and timestamps. For example:</p> <pre><code>from fake_factory.fraud.device_factory import DeviceLogFactory\n\nfactory = DeviceLogFactory()\ndevice_log = factory.generate()\nprint(device_log)\n</code></pre>"},{"location":"reference/libs/fake-factory/#transaction-factory","title":"Transaction Factory","text":"<p>The <code>TransactionFakeFactory</code> simulates transaction data with optional fraud labeling. It applies conditional fraud rules to raw transaction data for realistic risk simulation:</p> <pre><code>from fake_factory.fraud.transaction_factory import TransactionFakeFactory\n\ntransaction_factory = TransactionFakeFactory()\ntransaction = transaction_factory.generate(with_label=True)\nprint(transaction)\n</code></pre>"},{"location":"reference/libs/fake-factory/#user-profile-factory","title":"User Profile Factory","text":"<p>The <code>UserProfileFactory</code> generates user profiles with unique IDs and calculates a risk level based on factors such as credit score, signup date, and country:</p> <pre><code>from fake_factory.fraud.user_profile_factory import UserProfileFactory\n\nprofile_factory = UserProfileFactory()\nuser_profile = profile_factory.generate()\nprint(user_profile)\n</code></pre>"},{"location":"reference/libs/fake-factory/#configuration-details","title":"Configuration Details","text":"<ul> <li>Data Realism:   Each factory uses the Faker library to produce data that closely resembles real-world records.</li> <li>Fraud Rules:   The specialized fraud factories include multiple conditional branches to simulate different risk scenarios. For example, the TransactionFakeFactory can label transactions as fraudulent based on user compromise, card testing, or geographical anomalies.</li> <li>User ID Management:   The UserProfileFactory maintains a thread-safe queue of user IDs to ensure unique identifiers across generated profiles.</li> </ul>"},{"location":"reference/libs/fake-factory/#testing","title":"Testing","text":"<p>Unit tests are provided to validate the functionality and consistency of the data generators. To run the tests, navigate to the library\u2019s directory and execute:</p> <pre><code>npx nx test fake-factory\n</code></pre>"},{"location":"reference/libs/settings/emulator-settings/","title":"settings-emulator-settings","text":"<p>Project description here.</p>"},{"location":"reference/libs/shared/cliargs/","title":"CLI Arguments Parser","text":"<p>The CLI Arguments Parser Library provides a convenience function to generate a standard <code>argparse.ArgumentParser</code> with common command-line options such as verbose output, debug mode, logging level, and version information. It is designed to simplify the creation of consistent CLI interfaces across multiple applications.</p>"},{"location":"reference/libs/shared/cliargs/#features","title":"Features","text":"<ul> <li>Standard CLI Options: Pre-configured with commonly used command-line options.</li> <li>Consistent Interface: Ensures a uniform command-line interface for your applications.</li> <li>Ease of Integration: Quickly integrate the parser into any project with minimal configuration.</li> </ul>"},{"location":"reference/libs/shared/cliargs/#installation","title":"Installation","text":"<pre><code>npx nx run &lt;project&gt;:add --name shared-cliargs --local\n</code></pre>"},{"location":"reference/libs/shared/cliargs/#usage","title":"Usage","text":""},{"location":"reference/libs/shared/cliargs/#basic-setup","title":"Basic Setup","text":"<p>To create a standard argument parser for your application, import the <code>new_args_parser</code> function:</p> <pre><code>from cliargs.cliargs import new_args_parser\n\n# Create the argument parser with a brief description of your application\nparser = new_args_parser(\"Description of your application\")\nargs = parser.parse_args()\n\nif args.verbose:\n    print(\"Verbose mode enabled\")\n</code></pre>"},{"location":"reference/libs/shared/cliargs/#standard-cli-options","title":"Standard CLI Options","text":"<p>The parser includes the following command-line options:</p> <ul> <li><code>--verbose</code>: Enable verbose output.</li> <li><code>--debug</code>: Activate debug mode with detailed logging.</li> <li><code>--log-level</code>: Set the logging level. Acceptable values are \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", and \"CRITICAL\". Defaults to \"INFO\".</li> <li><code>--version</code>: Display the application's version and exit.</li> </ul>"},{"location":"reference/libs/shared/cliargs/#configuration-details","title":"Configuration Details","text":"<p>The <code>new_args_parser</code> function initializes an <code>argparse.ArgumentParser</code> with the provided description and adds the standard CLI options listed above. You can easily extend the parser with additional arguments as required by your application.</p>"},{"location":"reference/libs/shared/cliargs/#testing","title":"Testing","text":"<p>Unit tests are provided to ensure the argument parser functions correctly. To run the tests, navigate to the <code>libs/shared/cliargs</code> directory and execute:</p> <pre><code>npx nx test shared-cliargs\n</code></pre>"},{"location":"reference/libs/shared/logger/","title":"Logger","text":"<p>The Logger Library provides a simple and effective way to configure logging for your Python applications. It uses JSON formatting for log messages, making it easier to integrate with log management systems and enabling structured logging.</p>"},{"location":"reference/libs/shared/logger/#features","title":"Features","text":"<ul> <li>JSON Formatted Logging: Logs are output in a structured JSON format.</li> <li>Configurable Log Levels: Easily set the desired log level via function parameters or environment variables.</li> <li>Modular Integration: Quickly integrate the logger into any module by providing the module name.</li> <li>Propagation Control: Option to propagate log messages to parent loggers.</li> </ul>"},{"location":"reference/libs/shared/logger/#installation","title":"Installation","text":"<pre><code>npx nx run &lt;project&gt;:add --name shared-logger --local\n</code></pre>"},{"location":"reference/libs/shared/logger/#usage","title":"Usage","text":""},{"location":"reference/libs/shared/logger/#basic-setup","title":"Basic Setup","text":"<p>To set up logging with a custom module name, import the <code>setup_logging</code> function:</p> <pre><code>from logger.log import setup_logging\n\n# Create a logger for your module\nlogger = setup_logging(__name__)\n\n# Log an informational message\nlogger.info(\"This is an info message.\")\n</code></pre>"},{"location":"reference/libs/shared/logger/#environment-based-setup","title":"Environment-Based Setup","text":"<p>You can also create a logger that automatically reads the log level from the <code>LOG_LEVEL</code> environment variable. Use the <code>get_logger_from_env</code> function as follows:</p> <pre><code>from logger.log import get_logger_from_env\n\n# Create a logger that uses the LOG_LEVEL environment variable\nlogger = get_logger_from_env(__name__)\n\n# Log a debug message (if LOG_LEVEL is set to DEBUG)\nlogger.debug(\"This is a debug message.\")\n</code></pre> <p>Before running your application, set the <code>LOG_LEVEL</code> environment variable if needed:</p> <pre><code>export LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"reference/libs/shared/logger/#configuration-details","title":"Configuration Details","text":"<ul> <li>JSON Formatter:   The logger uses the following format for JSON logs:</li> </ul> <pre><code>%(levelname)s %(filename)s %(message)s\n</code></pre> <p>You can modify this format directly in the code by adjusting the formatter setup if a different structure is required.</p> <ul> <li>Propagation:   The <code>setup_logging</code> function accepts a <code>propagate</code> parameter. Set it to <code>True</code> if you want log messages to propagate to the parent logger.</li> </ul>"},{"location":"reference/libs/shared/logger/#testing","title":"Testing","text":"<p>Unit tests are provided to ensure that the logger functions correctly. To run the tests, navigate to the <code>libs/shared/logger</code> directory and execute:</p> <pre><code>npx nx test shared-logger\n</code></pre>"},{"location":"reference/services/data-emulator/","title":"Data Emulator Service","text":"<p>The Data Emulator Service orchestrates the emulation of data ingestion workflows. It provides a REST API\u2014built on FastAPI\u2014that enables external clients to trigger and manage emulator processes. The service integrates configuration management, logging, and resource setup (using Kafka and Minio) to simulate realistic data production. It leverages asynchronous background tasks and graceful signal handling for robust operation.</p>"},{"location":"reference/services/data-emulator/#overview","title":"Overview","text":"<p>The Data Emulator Service is designed to generate synthetic data for testing, development, and integration purposes. It consists of a primary process that:</p> <ul> <li>Parses command-line arguments using a custom CLI argument parser.</li> <li>Loads configuration settings via a custom <code>Settings</code> class.</li> <li>Sets up centralized logging.</li> <li>Spawns a child process to run the REST API server (using Uvicorn).</li> </ul> <p>The service uses an asynchronous signal handler to listen for termination signals (such as SIGINT and SIGTERM), ensuring that both the REST API server and any running tasks are shutdown gracefully.</p>"},{"location":"reference/services/data-emulator/#features","title":"Features","text":"<ul> <li> <p>RESTful API Interface:   Provides endpoints to interact with emulator use cases, allowing external triggering of long-running data emulation tasks.</p> </li> <li> <p>Modular Architecture:   Separates concerns by delegating configuration, logging, and resource initialization to dedicated modules. The REST API is run in an isolated child process.</p> </li> <li> <p>Configuration and Dependency Injection:   Uses a custom <code>Settings</code> class to configure external resources (Kafka, Minio) and logging. Command-line arguments control verbosity, debug mode, and log levels.</p> </li> <li> <p>Asynchronous Background Tasks:   Emulation tasks are scheduled asynchronously using FastAPI\u2019s BackgroundTasks, ensuring that API responses remain quick while the heavy lifting occurs in the background.</p> </li> <li> <p>Graceful Shutdown Handling:   A dedicated signal handler captures termination signals and coordinates the proper shutdown of the REST API process and any background tasks.</p> </li> </ul>"},{"location":"reference/services/data-emulator/#architecture","title":"Architecture","text":"<p>The service\u2019s main entry point performs the following steps:</p> <ol> <li> <p>Setup Service:</p> </li> <li> <p>Parses CLI arguments using <code>new_args_parser</code>.</p> </li> <li>Loads configuration settings from both CLI parameters and environment variables.</li> <li> <p>Sets up logging and propagates the log level to the application\u2019s environment.</p> </li> <li> <p>Start REST API Server:</p> </li> <li> <p>Spawns a child process to run the FastAPI REST server with Uvicorn.</p> </li> <li> <p>The REST API, which is built in a separate module (<code>api.emulator_rest_api</code>), receives the configuration via the app state.</p> </li> <li> <p>Signal Handling:</p> </li> <li> <p>Instantiates a <code>SignalHandler</code> that registers for termination signals.</p> </li> <li> <p>Asynchronously waits for a shutdown event; upon receiving a signal, it terminates the REST API child process and cleans up resources.</p> </li> <li> <p>Shutdown:</p> </li> <li>The main process joins the REST API process and exits gracefully.</li> </ol>"},{"location":"reference/services/data-emulator/#usage","title":"Usage","text":"<p>To build the current image for the Data Emulator Service, use:</p> <pre><code>npx nx image service-data-emulator\n</code></pre>"},{"location":"reference/services/data-emulator/#command-line-arguments","title":"Command-Line Arguments","text":"<p>The service supports CLI arguments (via the custom <code>new_args_parser</code>) for configuring log levels, verbosity, and debug modes. For example:</p> <pre><code>python main.py --log-level DEBUG --verbose\n</code></pre>"},{"location":"reference/services/data-emulator/#environment-configuration","title":"Environment Configuration","text":"<p>The service reads external resource settings (e.g., Kafka, Minio) from environment variables as well as the provided CLI arguments. For instance:</p> <ul> <li>Kafka:</li> <li><code>KAFKA_BOOTSTRAP_SERVERS</code></li> <li><code>KAFKA_USERNAME</code></li> <li><code>KAFKA_PASSWORD</code></li> <li>Minio:</li> <li><code>MINIO_ENDPOINT</code></li> <li><code>MINIO_ACCESS_KEY</code></li> <li><code>MINIO_SECRET_KEY</code></li> <li><code>MINIO_SECURE</code></li> </ul> <p>These values are loaded into the custom <code>Settings</code> class and assigned to the FastAPI app state before the REST API process starts.</p>"},{"location":"reference/services/data-emulator/#running-the-rest-api","title":"Running the REST API","text":"<p>The REST API server is launched as a child process using Uvicorn:</p> <pre><code>rest_app.state.config = config\nuvicorn.run(rest_app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n</code></pre> <p>This isolates the API layer while enabling the main process to manage service lifecycle and signal handling.</p>"},{"location":"reference/services/data-emulator/#signal-handling-and-graceful-shutdown","title":"Signal Handling and Graceful Shutdown","text":"<p>The service registers signal handlers for SIGINT and SIGTERM using an asynchronous <code>SignalHandler</code>. When a termination signal is received:</p> <ul> <li>The shutdown event is triggered.</li> <li>The REST API child process is terminated and joined.</li> <li>Any background tasks are allowed to complete, and resources are released before the service exits.</li> </ul>"},{"location":"reference/services/data-emulator/#logging","title":"Logging","text":"<p>The service configures logging early in the startup sequence. It sets the <code>LOG_LEVEL</code> environment variable and uses a custom logging setup to propagate messages. Verbose and debug modes are supported via CLI arguments.</p>"},{"location":"reference/services/data-emulator/#testing","title":"Testing","text":"<p>Unit tests are provided for the various modules including CLI argument parsing, configuration loading, REST API endpoints, and signal handling. To run the tests, execute:</p> <pre><code>npx nx test services-data-emulator\n</code></pre>"}]}